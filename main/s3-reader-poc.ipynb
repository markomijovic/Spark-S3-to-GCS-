{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf4eb50-64e0-4ed5-a92d-3b8edc0f70a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Guide How to use scala spark + s3 reading through spylon scala notebook and aws java sdk\n",
    "# get maven\n",
    "https://maven.apache.org/install.html\n",
    "```\n",
    "wget https://dlcdn.apache.org/maven/maven-3/3.8.4/binaries/apache-maven-3.8.4-bin.tar.gz\n",
    "tar xzvf apache-maven-3.8.4-bin.tar.gz\n",
    "```\n",
    "the, Add the bin directory of the created directory apache-maven-3.8.4 to the PATH environment variable.\n",
    "for example:\n",
    "```\n",
    "export PATH=\"$HOME/apache-maven-3.8.4/bin:$PATH\"\n",
    "```\n",
    "check if mvn is working\n",
    "```\n",
    "(base) jovyan@4ae1f87ce137:~$ mvn -v\n",
    "Apache Maven 3.8.4 (9b656c72d54e5bacbed989b64718c159fe39b537)\n",
    "Maven home: /home/jovyan/apache-maven-3.8.4\n",
    "Java version: 11.0.13, vendor: Ubuntu, runtime: /usr/lib/jvm/java-11-openjdk-amd64\n",
    "Default locale: en_US, platform encoding: UTF-8\n",
    "OS name: \"linux\", version: \"5.10.16.3-microsoft-standard-wsl2\", arch: \"amd64\", family: \"unix\"\n",
    "```\n",
    "\n",
    "# Install hadoop-aws JAR\n",
    "## create maven project\n",
    "https://docs.scala-lang.org/tutorials/scala-with-maven.html\n",
    "basically\n",
    "```\n",
    "mvn archetype:generate -DarchetypeGroupId=net.alchim31.maven -DarchetypeArtifactId=scala-archetype-simple\n",
    "```\n",
    "```\n",
    "Confirm properties configuration:\n",
    "groupId: com.capstone\n",
    "artifactId: s3.reader\n",
    "version: 1.0\n",
    "package: skip\n",
    "```\n",
    "\n",
    "\n",
    "## pom.xml under `work/s3.reader/pom.xml`\n",
    "in here, we need to insert this into dependencies\n",
    "```\n",
    "<dependency>\n",
    "  <groupId>software.amazon.awssdk</groupId>\n",
    "  <artifactId>aws-sdk-java</artifactId>\n",
    "  <version>2.17.112</version>\n",
    "</dependency>\n",
    "```\n",
    "for example\n",
    "```\n",
    "    <dependency>\n",
    "      <groupId>org.specs2</groupId>\n",
    "      <artifactId>specs2-junit_${scala.compat.version}</artifactId>\n",
    "      <version>${spec2.version}</version>\n",
    "      <scope>test</scope>\n",
    "    </dependency>\n",
    "    <dependency>\n",
    "      <groupId>software.amazon.awssdk</groupId>\n",
    "      <artifactId>aws-sdk-java</artifactId>\n",
    "      <version>2.17.112</version>\n",
    "    </dependency>\n",
    "  </dependencies>\n",
    "```\n",
    "get aws sdk https://aws.amazon.com/sdk-for-java/. \n",
    "next save the new pom file, then run \n",
    "`mvn clean install` or `mvn install`\n",
    "\n",
    "```\n",
    "(base) jovyan@4ae1f87ce137:~/work/s3.reader$ mvn install\n",
    "[INFO] Scanning for projects...\n",
    "[INFO] \n",
    "[INFO] -----------------------< com.capstone:s3.reader >-----------------------\n",
    "[INFO] Building s3.reader 1.0\n",
    "[INFO] --------------------------------[ jar ]---------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904a210-2971-43ea-b397-87add0ea0abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export PATH=\"$HOME/apache-maven-3.8.4/bin:$PATH\"\n",
    "!cd \"$HOME/work/s3.reader\" && mvn install\n",
    "!mvn -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298e7be-4887-478c-8fa1-91248259b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark: SparkSession = SparkSession.builder()\n",
    "      .master(\"local\")\n",
    "      .appName(\"SparkByExamples.com\")\n",
    "      .getOrCreate()\n",
    "val accessKeyID = \"\"\n",
    "val secretAccessKey=\"\"\n",
    "val s3Path=\"s3a://skip-capstone-2022/grocery_order_transaction_data/*.json\"\n",
    "spark.sparkContext\n",
    "     .hadoopConfiguration.set(\"fs.s3a.access.key\", accessKeyID)\n",
    "spark.sparkContext\n",
    "     .hadoopConfiguration.set(\"fs.s3a.secret.key\", secretAccessKey)\n",
    "spark.sparkContext\n",
    "      .hadoopConfiguration.set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c74e86-c091-425f-81c0-13e72fe4cca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val df = spark.read\n",
    ".format(\"json\")\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".load(s3Path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
